{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from newspaper import Article\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = '3306'\n",
    "username = 'root'\n",
    "password = ''\n",
    "database = 'news'\n",
    "\n",
    "# Create Connection to database\n",
    "# engine = create_engine('mysql+pymysql://'+username+\n",
    "# ':'+password+'@'+host+':'+port+'/'+database)\n",
    "\n",
    "# Note: We use pymysql instead of sqlalchemy because sqlalchemy\n",
    "# somehow don't allow the text query. Strange bug.\n",
    "conn = pymysql.connect(\n",
    "    host=host,\n",
    "    port=int(port),\n",
    "    user=username,\n",
    "    passwd=password,\n",
    "    db=database,\n",
    "    charset='utf8mb4')\n",
    "'''engine = create_engine('mysql+pymysql://root: @localhost:3306\n",
    "/news')'''\n",
    "\n",
    "engine = create_engine('mysql+pymysql://'+username+':'+password+'@'+host+':'+port+'/'+database)\n",
    "\n",
    "def run(sql):\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run(\"SELECT * FROM crime_news\")\n",
    "data['SOURCEURL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping masukan data ke tabel scrapping\n",
    "\n",
    "Colum table\n",
    "gid (Varchar), author (text), title (text), text (text), keywords (text), summary (text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "for d in data['SOURCEURL']:\n",
    "    print('Data:',number)\n",
    "    number += 1\n",
    "    gid = data['GLOBALEVENTID'][number-1] \n",
    "    try:\n",
    "        article = Article(d)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        authors = ''.join(article.authors)\n",
    "        title = ''.join(article.title)\n",
    "        text = ''.join(article.text)\n",
    "        keywords = ', '.join(article.keywords)\n",
    "        summary = ''.join(article.summary)\n",
    "        \n",
    "        \n",
    "        insert_string = \"INSERT INTO scraping VALUES ('\"+str(gid)+\"', '\"+re.sub(r\"[^a-zA-Z0-9,;.]+\", ' ', authors)+\"', '\"+re.sub(r\"[^a-zA-Z0-9,;.]+\", ' ', title)+\"', '\"+re.sub(r\"[^a-zA-Z0-9,;.]+\", ' ', text)+\"', '\"+re.sub(r\"[^a-zA-Z0-9,;.]+\", ' ', keywords)+\"', '\"+re.sub(r\"[^a-zA-Z0-9,;.]+\", ' ', summary)+\"')\"\n",
    "    \n",
    "        engine.execute(insert_string)\n",
    "    except:\n",
    "        print(\"Error:\", number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
